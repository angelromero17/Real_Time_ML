# -*- coding: utf-8 -*-
"""HW2_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/195i5fbPGYBO8AAJ61W_IQbUPReOjjaD0
"""

# Commented out IPython magic to ensure Python compatibility.
#Include the necessary libraries
# %matplotlib inline
from matplotlib import pyplot as plt
import numpy as np 
import torch

torch.set_printoptions(edgeitems=2, linewidth=75)
torch.manual_seed(123)

#Import CIFAR10 dataset
from torchvision import datasets
data_path = '../data-unversioned'
cirfar10 = datasets.CIFAR10(data_path, train=True, download=True)
cirfar10_val = datasets.CIFAR10(data_path, train=False, download=True)

#Display sample images from CIFAR10
class_names = ['airplane','automobile','bird','cat','deer','dog',
'frog','horse','ship','truck']

fig = plt.figure(figsize=(8,3))
num_classes = 10
for i in range(num_classes):
    ax = fig.add_subplot(2,5,1+i, xticks=[], yticks=[])
    ax.set_title(class_names[i])
    img = next(img for img, label in cirfar10 if label ==i)
    plt.imshow(img)
plt.show()

img, label = cirfar10[69]
plt.imshow(img)
plt.show()

"""Images to Tensor"""

from torchvision import transforms
tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.ToTensor())

#Normalizing the Data
img_t, _ = tensor_cifar10[69]
img_t.shape, img_t.dtype

#Determening torch size
imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)
imgs.shape

#Normalizing the Data
transforms_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.Compose([transforms.ToTensor(), 
transforms.Normalize((0.4915, 0.4823, 0.4468), 
                        (0.2470, 0.2435, 0.2616))
    ]))

transforms_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,transform=transforms.Compose([transforms.ToTensor(),
        transforms.Normalize((0.4915, 0.4823, 0.4468),
                             (0.2470, 0.2435, 0.2616))
    ]))

"""### Problem 2 Part1"""

#Model with single layer
import torch.nn as nn
n_out = 10

model = nn.Sequential(
    nn.Linear(3072, 512,), 
    nn.Tanh(), 
    nn.Linear(512, n_out)
)

#Model 1 output the features and output size (softmax to model)
n_out = 10
model1 = nn.Sequential(
    nn.Linear(3072, 512,), 
    nn.Tanh(), 
    nn.Linear(512, n_out),
    nn.LogSoftmax(dim=1)
)

#Training and displaying the results of the model for 200 epochs
import torch.optim as optim
train_loader = torch.utils.data.DataLoader(transforms_cifar10, batch_size=64,
                                           shuffle=True)

learning_rate = 1e-3
optimizer = optim.SGD(model1.parameters(), lr=learning_rate)
loss_fn = nn.NLLLoss()
n_epochs = 300

for epoch in range(n_epochs):
    for imgs, labels in train_loader:
        outputs = model1(imgs.view(imgs.shape[0], -1))
        loss = loss_fn(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    if epoch == 0 or epoch % 10 ==1:
      print("Epoch: %d, Loss: %f" % (epoch, float(loss)))

#Calculating accuracy
val_loader = torch.utils.data.DataLoader(transforms_cifar10_val, batch_size=64,
                                         shuffle=False)

correct = 0
total = 0

with torch.no_grad():
    for imgs, labels in val_loader:
        outputs = model1(imgs.view(imgs.shape[0], -1))
        _, predicted = torch.max(outputs, dim=1)
        total += labels.shape[0]
        correct += int((predicted == labels).sum())
    
print("Accuracy: %f" % (correct / total))

"""##Problem 2 Part 2"""

#Model with two layers
model2 = nn.Sequential(
            nn.Linear(3072, 1024),
            nn.Tanh(),
            nn.Linear(1024, 512),
            nn.Tanh(),
            nn.Linear(512, 128),
            nn.Tanh(),
            nn.Linear(128, 2))

#Training and displaying the results of the model for 200 epochs
train_loader = torch.utils.data.DataLoader(transforms_cifar10, batch_size=64,
                                           shuffle=True)
                                           

learning_rate = 1e-3
optimizer = optim.SGD(model.parameters(), lr=learning_rate)
loss_fn = nn.CrossEntropyLoss()
n_epochs = 300

for epoch in range(n_epochs):
    for imgs, labels in train_loader:
        outputs = model(imgs.view(imgs.shape[0], -1))
        loss = loss_fn(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    if epoch == 1 or epoch % 10 ==0:
      print("Epoch: %d, Loss: %f" % (epoch, float(loss)))

#Calculating accuracy
val_loader = torch.utils.data.DataLoader(transforms_cifar10_val, batch_size=64,
                                         shuffle=False)
correct = 0
total = 0

with torch.no_grad():
    for imgs, labels in val_loader:
        outputs = model2(imgs.view(imgs.shape[0], -1))
        _, predicted = torch.max(outputs, dim=1)
        total += labels.shape[0]
        correct += int((predicted == labels).sum())
        
print("Accuracy: %f" % (correct / total))